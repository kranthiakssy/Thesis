{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1353,
     "status": "ok",
     "timestamp": 1621175748416,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "qa5WMbkMP-f0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1936,
     "status": "ok",
     "timestamp": 1621175749003,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "Zxnz-RYuQId2"
   },
   "outputs": [],
   "source": [
    "class OUActionNoise(object):\n",
    "    def __init__(self, mu, sigma=0.15, theta=.2, dt=1e-2, x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "            self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(\n",
    "                                                            self.mu, self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 3132,
     "status": "ok",
     "timestamp": 1621175750204,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "hdObLB0wQIg5"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, max_size, input_shape, n_actions):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_shape))\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_shape))\n",
    "        self.action_memory = np.zeros((self.mem_size, n_actions))\n",
    "        self.reward_memory = np.zeros(self.mem_size)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = 1 - done\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "\n",
    "        batch = np.random.choice(max_mem, batch_size)\n",
    "\n",
    "        states = self.state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        terminal = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, states_, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 3132,
     "status": "ok",
     "timestamp": 1621175750205,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "oInZPPkKQIjq"
   },
   "outputs": [],
   "source": [
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, beta, input_dims, fc1_dims, fc2_dims, n_actions, name,\n",
    "                 chkpt_dir='tmp/ddpg/'):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir,name+'_ddpg')\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        f1 = 1./np.sqrt(self.fc1.weight.data.size()[0])\n",
    "        T.nn.init.uniform_(self.fc1.weight.data, -f1, f1)\n",
    "        T.nn.init.uniform_(self.fc1.bias.data, -f1, f1)\n",
    "        #self.fc1.weight.data.uniform_(-f1, f1)\n",
    "        #self.fc1.bias.data.uniform_(-f1, f1)\n",
    "        self.bn1 = nn.LayerNorm(self.fc1_dims)\n",
    "\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        f2 = 1./np.sqrt(self.fc2.weight.data.size()[0])\n",
    "        #f2 = 0.002\n",
    "        T.nn.init.uniform_(self.fc2.weight.data, -f2, f2)\n",
    "        T.nn.init.uniform_(self.fc2.bias.data, -f2, f2)\n",
    "        #self.fc2.weight.data.uniform_(-f2, f2)\n",
    "        #self.fc2.bias.data.uniform_(-f2, f2)\n",
    "        self.bn2 = nn.LayerNorm(self.fc2_dims)\n",
    "\n",
    "        self.action_value = nn.Linear(self.n_actions, self.fc2_dims)\n",
    "        f3 = 0.003\n",
    "        self.q = nn.Linear(self.fc2_dims, 1)\n",
    "        T.nn.init.uniform_(self.q.weight.data, -f3, f3)\n",
    "        T.nn.init.uniform_(self.q.bias.data, -f3, f3)\n",
    "        #self.q.weight.data.uniform_(-f3, f3)\n",
    "        #self.q.bias.data.uniform_(-f3, f3)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=beta)\n",
    "        self.device = 'cpu' #T.device('cuda:0' if T.cuda.is_available() else 'cuda:1')\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        state_value = self.fc1(state)\n",
    "        state_value = self.bn1(state_value)\n",
    "        state_value = F.relu(state_value)\n",
    "        state_value = self.fc2(state_value)\n",
    "        state_value = self.bn2(state_value)\n",
    "\n",
    "        action_value = F.relu(self.action_value(action))\n",
    "        state_action_value = F.relu(T.add(state_value, action_value))\n",
    "        state_action_value = self.q(state_action_value)\n",
    "\n",
    "        return state_action_value\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        print('... saving checkpoint ...')\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        print('... loading checkpoint ...')\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 3130,
     "status": "ok",
     "timestamp": 1621175750207,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "qG-LSO6BQImU"
   },
   "outputs": [],
   "source": [
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, alpha, input_dims, fc1_dims, fc2_dims, n_actions, name,\n",
    "                 chkpt_dir='tmp/ddpg/'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir,name+'_ddpg')\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        f1 = 1./np.sqrt(self.fc1.weight.data.size()[0])\n",
    "        T.nn.init.uniform_(self.fc1.weight.data, -f1, f1)\n",
    "        T.nn.init.uniform_(self.fc1.bias.data, -f1, f1)\n",
    "        #self.fc1.weight.data.uniform_(-f1, f1)\n",
    "        #self.fc1.bias.data.uniform_(-f1, f1)\n",
    "        self.bn1 = nn.LayerNorm(self.fc1_dims)\n",
    "\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        #f2 = 0.002\n",
    "        f2 = 1./np.sqrt(self.fc2.weight.data.size()[0])\n",
    "        T.nn.init.uniform_(self.fc2.weight.data, -f2, f2)\n",
    "        T.nn.init.uniform_(self.fc2.bias.data, -f2, f2)\n",
    "        #self.fc2.weight.data.uniform_(-f2, f2)\n",
    "        #self.fc2.bias.data.uniform_(-f2, f2)\n",
    "        self.bn2 = nn.LayerNorm(self.fc2_dims)\n",
    "\n",
    "        #f3 = 0.004\n",
    "        f3 = 0.003\n",
    "        self.mu = nn.Linear(self.fc2_dims, self.n_actions)\n",
    "        T.nn.init.uniform_(self.mu.weight.data, -f3, f3)\n",
    "        T.nn.init.uniform_(self.mu.bias.data, -f3, f3)\n",
    "        #self.mu.weight.data.uniform_(-f3, f3)\n",
    "        #self.mu.bias.data.uniform_(-f3, f3)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = 'cpu' #T.device('cuda:0' if T.cuda.is_available() else 'cuda:1')\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.fc1(state)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = T.tanh(self.mu(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        print('... saving checkpoint ...')\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        print('... loading checkpoint ...')\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 3128,
     "status": "ok",
     "timestamp": 1621175750208,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "PgRiOsB0QIpA"
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, alpha, beta, input_dims, tau, env, gamma=0.99,\n",
    "                 n_actions=2, max_size=1000000, layer1_size=400,\n",
    "                 layer2_size=300, batch_size=64):\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.memory = ReplayBuffer(max_size, input_dims, n_actions)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.actor = ActorNetwork(alpha, input_dims, layer1_size,\n",
    "                                  layer2_size, n_actions=n_actions,\n",
    "                                  name='Actor')\n",
    "        self.critic = CriticNetwork(beta, input_dims, layer1_size,\n",
    "                                    layer2_size, n_actions=n_actions,\n",
    "                                    name='Critic')\n",
    "\n",
    "        self.target_actor = ActorNetwork(alpha, input_dims, layer1_size,\n",
    "                                         layer2_size, n_actions=n_actions,\n",
    "                                         name='TargetActor')\n",
    "        self.target_critic = CriticNetwork(beta, input_dims, layer1_size,\n",
    "                                           layer2_size, n_actions=n_actions,\n",
    "                                           name='TargetCritic')\n",
    "\n",
    "        self.noise = OUActionNoise(mu=np.zeros(n_actions))\n",
    "\n",
    "        self.update_network_parameters(tau=1)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        self.actor.eval()\n",
    "        observation = T.tensor(observation, dtype=T.float).to(self.actor.device)\n",
    "        mu = self.actor.forward(observation).to(self.actor.device)\n",
    "        mu_prime = mu + T.tensor(self.noise(),\n",
    "                                 dtype=T.float).to(self.actor.device)\n",
    "        self.actor.train()\n",
    "        return mu_prime.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "\n",
    "    def learn(self):\n",
    "        if self.memory.mem_cntr < self.batch_size:\n",
    "            return\n",
    "        state, action, reward, new_state, done = \\\n",
    "                                      self.memory.sample_buffer(self.batch_size)\n",
    "\n",
    "        reward = T.tensor(reward, dtype=T.float).to(self.critic.device)\n",
    "        done = T.tensor(done).to(self.critic.device)\n",
    "        new_state = T.tensor(new_state, dtype=T.float).to(self.critic.device)\n",
    "        action = T.tensor(action, dtype=T.float).to(self.critic.device)\n",
    "        state = T.tensor(state, dtype=T.float).to(self.critic.device)\n",
    "\n",
    "        self.target_actor.eval()\n",
    "        self.target_critic.eval()\n",
    "        self.critic.eval()\n",
    "        target_actions = self.target_actor.forward(new_state)\n",
    "        critic_value_ = self.target_critic.forward(new_state, target_actions)\n",
    "        critic_value = self.critic.forward(state, action)\n",
    "\n",
    "        target = []\n",
    "        for j in range(self.batch_size):\n",
    "            target.append(reward[j] + self.gamma*critic_value_[j]*done[j])\n",
    "        target = T.tensor(target).to(self.critic.device)\n",
    "        target = target.view(self.batch_size, 1)\n",
    "\n",
    "        self.critic.train()\n",
    "        self.critic.optimizer.zero_grad()\n",
    "        critic_loss = F.mse_loss(target, critic_value)\n",
    "        critic_loss.backward()\n",
    "        self.critic.optimizer.step()\n",
    "\n",
    "        self.critic.eval()\n",
    "        self.actor.optimizer.zero_grad()\n",
    "        mu = self.actor.forward(state)\n",
    "        self.actor.train()\n",
    "        actor_loss = -self.critic.forward(state, mu)\n",
    "        actor_loss = T.mean(actor_loss)\n",
    "        actor_loss.backward()\n",
    "        self.actor.optimizer.step()\n",
    "\n",
    "        self.update_network_parameters()\n",
    "\n",
    "    def update_network_parameters(self, tau=None):\n",
    "        if tau is None:\n",
    "            tau = self.tau\n",
    "\n",
    "        actor_params = self.actor.named_parameters()\n",
    "        critic_params = self.critic.named_parameters()\n",
    "        target_actor_params = self.target_actor.named_parameters()\n",
    "        target_critic_params = self.target_critic.named_parameters()\n",
    "\n",
    "        critic_state_dict = dict(critic_params)\n",
    "        actor_state_dict = dict(actor_params)\n",
    "        target_critic_dict = dict(target_critic_params)\n",
    "        target_actor_dict = dict(target_actor_params)\n",
    "\n",
    "        for name in critic_state_dict:\n",
    "            critic_state_dict[name] = tau*critic_state_dict[name].clone() + \\\n",
    "                                      (1-tau)*target_critic_dict[name].clone()\n",
    "\n",
    "        self.target_critic.load_state_dict(critic_state_dict)\n",
    "\n",
    "        for name in actor_state_dict:\n",
    "            actor_state_dict[name] = tau*actor_state_dict[name].clone() + \\\n",
    "                                      (1-tau)*target_actor_dict[name].clone()\n",
    "        self.target_actor.load_state_dict(actor_state_dict)\n",
    "\n",
    "        \"\"\"\n",
    "        #Verify that the copy assignment worked correctly\n",
    "        target_actor_params = self.target_actor.named_parameters()\n",
    "        target_critic_params = self.target_critic.named_parameters()\n",
    "        critic_state_dict = dict(target_critic_params)\n",
    "        actor_state_dict = dict(target_actor_params)\n",
    "        print('\\nActor Networks', tau)\n",
    "        for name, param in self.actor.named_parameters():\n",
    "            print(name, T.equal(param, actor_state_dict[name]))\n",
    "        print('\\nCritic Networks', tau)\n",
    "        for name, param in self.critic.named_parameters():\n",
    "            print(name, T.equal(param, critic_state_dict[name]))\n",
    "        input()\n",
    "        \"\"\"\n",
    "    def save_models(self):\n",
    "        self.actor.save_checkpoint()\n",
    "        self.target_actor.save_checkpoint()\n",
    "        self.critic.save_checkpoint()\n",
    "        self.target_critic.save_checkpoint()\n",
    "\n",
    "    def load_models(self):\n",
    "        self.actor.load_checkpoint()\n",
    "        self.target_actor.load_checkpoint()\n",
    "        self.critic.load_checkpoint()\n",
    "        self.target_critic.load_checkpoint()\n",
    "\n",
    "    def check_actor_params(self):\n",
    "        current_actor_params = self.actor.named_parameters()\n",
    "        current_actor_dict = dict(current_actor_params)\n",
    "        original_actor_dict = dict(self.original_actor.named_parameters())\n",
    "        original_critic_dict = dict(self.original_critic.named_parameters())\n",
    "        current_critic_params = self.critic.named_parameters()\n",
    "        current_critic_dict = dict(current_critic_params)\n",
    "        print('Checking Actor parameters')\n",
    "\n",
    "        for param in current_actor_dict:\n",
    "            print(param, T.equal(original_actor_dict[param], current_actor_dict[param]))\n",
    "        print('Checking critic parameters')\n",
    "        for param in current_critic_dict:\n",
    "            print(param, T.equal(original_critic_dict[param], current_critic_dict[param]))\n",
    "        input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 3127,
     "status": "ok",
     "timestamp": 1621175750209,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "yWm-ZVT7QIrt"
   },
   "outputs": [],
   "source": [
    "def plotLearning(scores, filename, x=None, window=5):   \n",
    "    N = len(scores)\n",
    "    running_avg = np.empty(N)\n",
    "    for t in range(N):\n",
    "\t    running_avg[t] = np.mean(scores[max(0, t-window):(t+1)])\n",
    "    if x is None:\n",
    "        x = [i for i in range(N)]\n",
    "    plt.ylabel('Score')       \n",
    "    plt.xlabel('Game')                     \n",
    "    plt.plot(x, running_avg)\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7568,
     "status": "ok",
     "timestamp": 1621175754658,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "OULch1uPVa6b",
    "outputId": "26c95d9c-fd09-45ad-fe91-7b47009d1b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Box2D\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/1b/ce95bb5d1807d4d85af8d0c90050add1a77124459f8097791f0c39136d53/Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 4.1MB/s \n",
      "\u001b[?25hInstalling collected packages: Box2D\n",
      "Successfully installed Box2D-2.3.10\n"
     ]
    }
   ],
   "source": [
    "!pip install Box2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 752772,
     "status": "ok",
     "timestamp": 1621176499872,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "G7gQebHPQIuQ",
    "outputId": "e6776405-273f-4ce0-ac3f-241a2bf05a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n",
      "episode  0 score -600.46 trailing 100 games avg -600.460\n",
      "episode  1 score -477.76 trailing 100 games avg -539.109\n",
      "episode  2 score -271.95 trailing 100 games avg -450.056\n",
      "episode  3 score -222.73 trailing 100 games avg -393.223\n",
      "episode  4 score -178.60 trailing 100 games avg -350.298\n",
      "episode  5 score -111.32 trailing 100 games avg -310.468\n",
      "episode  6 score -315.59 trailing 100 games avg -311.201\n",
      "episode  7 score -551.61 trailing 100 games avg -341.252\n",
      "episode  8 score -331.14 trailing 100 games avg -340.129\n",
      "episode  9 score -421.16 trailing 100 games avg -348.232\n",
      "episode  10 score -233.70 trailing 100 games avg -337.820\n",
      "episode  11 score -385.63 trailing 100 games avg -341.804\n",
      "episode  12 score -377.51 trailing 100 games avg -344.551\n",
      "episode  13 score -334.79 trailing 100 games avg -343.854\n",
      "episode  14 score -388.83 trailing 100 games avg -346.852\n",
      "episode  15 score -114.58 trailing 100 games avg -332.335\n",
      "episode  16 score -401.33 trailing 100 games avg -336.393\n",
      "episode  17 score -427.62 trailing 100 games avg -341.461\n",
      "episode  18 score -468.05 trailing 100 games avg -348.124\n",
      "episode  19 score -470.00 trailing 100 games avg -354.218\n",
      "episode  20 score -254.43 trailing 100 games avg -349.466\n",
      "episode  21 score -587.56 trailing 100 games avg -360.289\n",
      "episode  22 score -1186.81 trailing 100 games avg -396.225\n",
      "episode  23 score -995.30 trailing 100 games avg -421.186\n",
      "episode  24 score -483.09 trailing 100 games avg -423.662\n",
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n",
      "episode  25 score -136.96 trailing 100 games avg -412.635\n",
      "episode  26 score -383.04 trailing 100 games avg -411.539\n",
      "episode  27 score -641.01 trailing 100 games avg -419.735\n",
      "episode  28 score -184.69 trailing 100 games avg -411.630\n",
      "episode  29 score -546.24 trailing 100 games avg -416.117\n",
      "episode  30 score -452.75 trailing 100 games avg -417.299\n",
      "episode  31 score -521.88 trailing 100 games avg -420.567\n",
      "episode  32 score -440.78 trailing 100 games avg -421.179\n",
      "episode  33 score -598.65 trailing 100 games avg -426.399\n",
      "episode  34 score -544.75 trailing 100 games avg -429.781\n",
      "episode  35 score -829.39 trailing 100 games avg -440.881\n",
      "episode  36 score -620.83 trailing 100 games avg -445.744\n",
      "episode  37 score -405.27 trailing 100 games avg -444.679\n",
      "episode  38 score -431.87 trailing 100 games avg -444.351\n",
      "episode  39 score -399.52 trailing 100 games avg -443.230\n",
      "episode  40 score -407.09 trailing 100 games avg -442.348\n",
      "episode  41 score -451.86 trailing 100 games avg -442.575\n",
      "episode  42 score -311.72 trailing 100 games avg -439.532\n",
      "episode  43 score -334.27 trailing 100 games avg -437.139\n",
      "episode  44 score -373.39 trailing 100 games avg -435.723\n",
      "episode  45 score -433.85 trailing 100 games avg -435.682\n",
      "episode  46 score -354.04 trailing 100 games avg -433.945\n",
      "episode  47 score -315.19 trailing 100 games avg -431.471\n",
      "episode  48 score -350.04 trailing 100 games avg -429.809\n",
      "episode  49 score -372.64 trailing 100 games avg -428.666\n",
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n",
      "episode  50 score -312.26 trailing 100 games avg -426.383\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('LunarLanderContinuous-v2') #('LunarLanderContinuous-v2')\n",
    "agent = Agent(alpha=0.000025, beta=0.00025, input_dims=[8], tau=0.001, env=env,\n",
    "              batch_size=64,  layer1_size=400, layer2_size=300, n_actions=2)\n",
    "\n",
    "#agent.load_models()\n",
    "np.random.seed(0)\n",
    "\n",
    "score_history = []\n",
    "for i in range(51): #1000 episodes\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        act = agent.choose_action(obs)\n",
    "        new_state, reward, done, info = env.step(act)\n",
    "        agent.remember(obs, act, reward, new_state, int(done))\n",
    "        agent.learn()\n",
    "        score += reward\n",
    "        obs = new_state\n",
    "        #env.render()\n",
    "    score_history.append(score)\n",
    "\n",
    "    if i % 25 == 0:\n",
    "        agent.save_models()\n",
    "\n",
    "    print('episode ', i, 'score %.2f' % score,\n",
    "          'trailing 100 games avg %.3f' % np.mean(score_history[-100:]))\n",
    "\n",
    "filename = 'LunarLander-alpha000025-beta00025-400-300.png'\n",
    "plotLearning(score_history, filename, window=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 752774,
     "status": "ok",
     "timestamp": 1621176499877,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "FNQykmOBQIwz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 752773,
     "status": "ok",
     "timestamp": 1621176499879,
     "user": {
      "displayName": "KRANTHI KUMAR PASAGADUGULA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghh6OnprjKXP4JzW71OLAwD3M3RDYZV9iSkhw18=s64",
      "userId": "10858457511797102609"
     },
     "user_tz": -330
    },
    "id": "HzXQW9GSQIzS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOc+dA1FJrYV5eanHBiUa9B",
   "collapsed_sections": [],
   "mount_file_id": "1tHRWVcJXDDXuFmSTbIZ_NF4eogJJJDXX",
   "name": "DDPG_Lunar-Lander_20210507.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "drl37",
   "language": "python",
   "name": "drl37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
